= Greenplum GPFDist Sink Module

== Introduction

The gpfdist sink allows you to stream data in parallel to either Pivotal Greenplum DB
 or Pivotal HAWQ.  Internally, this sink creates a custom http listener that supports 
the `gpfdist` protcol and schedules a task that orchestrates a `gploadd` session in the 
same way it is done natively in Greenplum.

No data is written into temporary files and all data is kept in stream buffers waiting 
to get inserted into Greenplum DB or HAWQ.  If there are no existing load sessions from Greenplum, 
the sink will block until such sessions are established.

NOTE: This is currently work in progress so expect issues until bugs
are ironed out.  Notable missing features that are planned to be added are append and merge support.

== Requirements

* Spring XD version 1.1.x or later.  http://docs.spring.io/spring-xd/docs/current/reference/html/#getting-started[Instructions 1.1.2], http://docs.spring.io/spring-xd/docs/current/reference/html/#getting-started[Instructions 1.2.0.M1]

== Build and Install

To build, clone this repository. Then cd to `gpfdist` and type

[source,text]
----
$./gradlew build
----

The uber-jar will be in `[spring-xd-modules-dir]/gpfdist/build/libs/gpfdist-1.0.0.BUILD-SNAPSHOT.jar`.  To install and register the module, use the `module upload` Spring XD shell command.  

Start Spring XD and the shell.  In the shell type the following to upload the module

[source,text]
----
xd:>module upload --file [path-to]/gpfdist-1.0.0.BUILD-SNAPSHOT.jar --name gpfdist --type sink
Successfully uploaded module 'sink:throughput'
----

You can get information about the available module options:

----
xd:>module info --name sink:gpfdist
Information about sink module 'gpfdist':

  Option Name  Description                                           Default    Type
  -----------  ----------------------------------------------------- ---------  --------
  batchCount   batch count                                           100        int
  batchPeriod  batch period                                          10         int
  batchTimeout batch timeout                                         4          int
  controlFile  path to yaml control file                             <none>     String
  dbHost       database host                                         localhost  String
  dbName       database name                                         gpadmin    String
  dbPassword   database password                                     gpadmin    String
  dbPort       database port                                         5432       int
  dbUser       database user                                         gpadmin    String
  delimiter    data line delimiter                                   "\n"       String
  flushCount   flush item count                                      100        int
  flushTime    flush item time                                       2          int
  port         gpfdist listen port                                   0          int
  rateInterval enable transfer rate interval                         0          int
  table        target database table                                 <none>     String
----

=== Explanation of Options

The options `flushCount` and `flushTime` are used to determine when to flush
data that is buffered in an internal 
http://projectreactor.io/docs/reference/streams.html#basics[Reactor stream] to 
the http connection.  Data is flushed based on if the count value has been reached 
or the time specified has elapsed.  Note that with too high a value, memory consumption
will go up.  Too small a value combined with a low ingestion rate will result in data 
being inserted into the database less frequently.

`batchCount` defines the maximum count of aggregated windows the client
takes before the internal Reactor stream and http channel is closed.

`batchTimeout` defines how many seconds each http connection should be
kept alive if no data is streamed to a client. Use this together with
`batchCount` to estimate how long each loading session should last.

`batchPeriod` defines how many seconds a task running load operation
should sleep in between a loads.

`delimiter` is used to postfix incoming data with a line termination
because Greenplum expects line terminated data.

`controlFile` can be used to introduce more parameters for a load
operation. For simple use cases, the `table` property can be used.

`rateInterval` if set, enables rate logging passing through sink.



== Example usage

The `load-generator-gpfdist` source can be used to send dummy test data to the `gpfdist` sink.

Using `psql`, create the following table with a simple schema that matches the data produced by the
`load-generator-string` source, two integer values, a producer ID and a timestamp separated by a tab.

[source,text]
----
create table xdsink (date integer, time integer) distributed randomly;
----

Now create the stream definition and deploy.

[source,text]
----
xd:>stream create --name gpfdiststream --definition "load-generator-string --messageCount=10000000 --producers=1 --recordType=counter | gpfdist --dbHost=192.168.70.138 --table=xdsink --batchTimeout=5 --batchCount=1000 --batchPeriod=0 --flushCount=200 --flushTime=2" --deploy
Created and deployed new stream 'gpfdiststream'
----
////
xd:>stream create --name gpfdiststream --definition "load-generator-string --messageCount=10000000 --producers=1 |gpfdist --dbHost=mdw --table=xdsink --batchTime=5 --batchPeriod=1 --flushCount=200 --flushTime=2 --rateInterval=1000000" --deploy
////

In this XD stream we send 10M messages from the `load-generator-string` source to the `gpfdist` sink.
We roughly keep load session alive for 5 seconds while flushing data after 2s or 200 entries which ever
comes first and sleep 0s in between load sessions.

You will see log output such as
[source,text]
----
2015-04-29 17:29:12,173 1.2.0.M1  INFO sqlTaskScheduler-1 support.CleanableJdbcOperations - CREATE READABLE EXTERNAL TABLE xdsink_ext_706806a0_7057_45bc_9e1d_3a79e73b26f8 ( LIKE xdsink ) LOCATION('gpfdist://192.168.70.137:35609/data') FORMAT 'TEXT' ( DELIMITER '\u0009' )
2015-04-29 17:29:12,822 1.2.0.M1  INFO pool-12-thread-1 gpfdist.GPFDistMessageHandler - METER 1m/185287.4620522582 mean/185271.18436926394
2015-04-29 17:29:19,213 1.2.0.M1  INFO sqlTaskScheduler-1 support.CleanableJdbcOperations - DROP EXTERNAL TABLE xdsink_ext_706806a0_7057_45bc_9e1d_3a79e73b26f8
----

`gpfdist` sink currently contains a throughput meter for this POC to
get perf numbers. In this case it is showing about 270K/sec
messages per second to be transferred from XD into Greenplum.



== Performance Notes

On a Lenovo W540, Spring XD singlenode, `load-generator-string | gpfdist` inserted data at ~ 540K/sec. 
The underlying message handler in the gpfdist sink is able to achieve ~1.2M/sec, which is comprable to
the use of the native gpload client.  Additional performance optimizations when used within an XD stream
are on the roadmap.

== Implementation Notes

Within a `gpfdist` sink we have a Reactor based stream where data is published from the incoming SI channel.
This channel receives data from the Message Bus.  The Reactor stream is then connected to `Netty` based 
http channel adapters so that when a new http connection is established, the Reactor stream is flushed and balanced among
existing http clients.  When `Greenplum` does a load from an external table, each segment will initiate 
a http connection and start loading data.  The net effect is that incoming data is automatically spread 
among the Greenplum segments.



